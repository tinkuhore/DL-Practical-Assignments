{"cells":[{"cell_type":"markdown","metadata":{"id":"npJuBdgiJvp7"},"source":["\n","# **Project Objective** \n","\n"]},{"cell_type":"markdown","metadata":{"id":"t71AfI-HJluN"},"source":["**Practical Assignment**\n","**Objective:** - Image Classification with CIFAR 100\n","\n","This dataset is just like the CIFAR-10, except it has 100 classes containing 600\n","images each. There are 500 training images and 100 testing images per class.\n","The 100 classes in the CIFAR-100 are grouped into 20 superclasses. Each image\n","comes with a &quot;fine&quot; label (the class to which it belongs) and a &quot;coarse&quot; label\n","(the superclass to which it belongs).\n","\n","**Dataset Link:** - https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n","The dataset is not direct images. Please decode it using your own techniques.\n","\n","**Task:** - Create a Web Application using Flask. Use the end user should be able\n","to upload an image and get results with the prediction score.\n","\n","**Deployment:** - Any Free Platform(Try to look out for free options.)\n","\n","**Assignment Submission:** - Only submit the hosted app link."]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":29681,"status":"ok","timestamp":1681837336404,"user":{"displayName":"Tinku Hore","userId":"01939873183751343085"},"user_tz":-330},"id":"tfoyGtAGKEME","outputId":"d589eb61-a78e-4abe-b24c-026639d08edb"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","metadata":{"id":"aONm91peJmob"},"source":["# **Data Collection**"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":0},"executionInfo":{"elapsed":2586,"status":"ok","timestamp":1681840705613,"user":{"displayName":"Tinku Hore","userId":"01939873183751343085"},"user_tz":-330},"id":"2NES4VwZJluT","outputId":"f4df75bf-3c95-4616-aa77-adcafa7d99b2"},"outputs":[{"data":{"image/png":"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","text/plain":["<PIL.Image.Image image mode=RGB size=32x32 at 0x7F6A701E1C70>"]},"metadata":{},"output_type":"display_data"},{"data":{"image/png":"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","text/plain":["<PIL.Image.Image image mode=RGB size=32x32 at 0x7F6A701E1550>"]},"metadata":{},"output_type":"display_data"},{"data":{"image/png":"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","text/plain":["<PIL.Image.Image image mode=RGB size=32x32 at 0x7F6A701E19A0>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["-1"]},"execution_count":2,"metadata":{},"output_type":"execute_result"}],"source":["import pickle\n","import numpy as np\n","import cv2\n","from google.colab.patches import cv2_imshow\n","\n","def unpickle(file):\n","    with open(file, 'rb') as fo:\n","        dict = pickle.load(fo, encoding='bytes')\n","    return dict\n","\n","data_dir = '/content/drive/MyDrive/DL/Assignment1/cifar-10-batches-py/'\n","\n","# Load training data\n","train_images = []\n","train_labels = []\n","for i in range(1, 6):\n","    filename = data_dir + f'data_batch_{i}'\n","    batch = unpickle(filename)\n","    batch_images = batch[b'data'].reshape((-1, 3, 32, 32)).transpose((0, 2, 3, 1))\n","    train_images.append(batch_images)\n","    train_labels += batch[b'labels']\n","train_images = np.concatenate(train_images, axis=0)\n","train_labels = np.array(train_labels)\n","\n","# Load test data\n","test_batch = unpickle(data_dir + 'test_batch')\n","test_images = test_batch[b'data'].reshape((-1, 3, 32, 32)).transpose((0, 2, 3, 1))\n","test_labels = np.array(test_batch[b'labels'])\n","\n","# Visualize some images\n","for i in range(3):\n","    img = train_images[i]\n","    label = train_labels[i]\n","    cv2_imshow(img)   #(f'Image {i}, Label {label}', img)\n","cv2.waitKey(0)\n"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1681840705614,"user":{"displayName":"Tinku Hore","userId":"01939873183751343085"},"user_tz":-330},"id":"uT2iGgIDOep_","outputId":"35e5c2dd-7d9a-4fea-8231-080d92cede15"},"outputs":[{"data":{"text/plain":["(50000, 32, 32, 3)"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["train_images.shape"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1681840705614,"user":{"displayName":"Tinku Hore","userId":"01939873183751343085"},"user_tz":-330},"id":"i-wk-L9_LaAx","outputId":"f94c7a6d-f486-4206-fd52-a59fc1637614"},"outputs":[{"data":{"text/plain":["(32, 32, 3)"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["train_images[11].shape"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1681840705614,"user":{"displayName":"Tinku Hore","userId":"01939873183751343085"},"user_tz":-330},"id":"fWejz7seLk-x","outputId":"24ba71b3-89df-46e4-8de3-2186b8302efa"},"outputs":[{"data":{"text/plain":["array([[[142, 149, 152],\n","        [172, 172, 167],\n","        [176, 168, 154],\n","        ...,\n","        [216, 212, 211],\n","        [198, 194, 193],\n","        [205, 202, 200]],\n","\n","       [[191, 190, 192],\n","        [196, 192, 190],\n","        [174, 166, 159],\n","        ...,\n","        [229, 222, 220],\n","        [222, 215, 213],\n","        [217, 210, 207]],\n","\n","       [[220, 212, 212],\n","        [217, 209, 208],\n","        [192, 183, 182],\n","        ...,\n","        [224, 214, 209],\n","        [225, 214, 210],\n","        [218, 208, 203]],\n","\n","       ...,\n","\n","       [[197, 152, 136],\n","        [196, 152, 135],\n","        [201, 156, 140],\n","        ...,\n","        [200, 165, 146],\n","        [199, 165, 146],\n","        [205, 164, 150]],\n","\n","       [[196, 157, 139],\n","        [191, 152, 135],\n","        [193, 154, 136],\n","        ...,\n","        [198, 164, 144],\n","        [199, 165, 145],\n","        [201, 161, 146]],\n","\n","       [[186, 150, 133],\n","        [182, 147, 130],\n","        [174, 139, 121],\n","        ...,\n","        [158, 124, 105],\n","        [158, 125, 106],\n","        [163, 125, 111]]], dtype=uint8)"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["train_images[11]"]},{"cell_type":"markdown","metadata":{"id":"MJev9MXqMVvh"},"source":["# **Data Preparation**\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VM3RTTN_MbwZ"},"outputs":[],"source":["# Normalize the images\n","train_images = train_images.astype('float32') / 255.0\n","test_images = test_images.astype('float32') / 255.0"]},{"cell_type":"markdown","metadata":{"id":"jTotsem2L655"},"source":["# **Model Training**"]},{"cell_type":"markdown","metadata":{"id":"ltfgeC6TOTxg"},"source":["## Experiment 1\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":522668,"status":"ok","timestamp":1681809197974,"user":{"displayName":"Tinku Hore","userId":"01939873183751343085"},"user_tz":-330},"id":"hwPsIt5UMBal","outputId":"8a5757a9-833d-4fd4-965a-5dc4cd271708"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/50\n","781/781 [==============================] - 104s 111ms/step - loss: 3.9675 - accuracy: 0.0980 - val_loss: 2.3025 - val_accuracy: 0.1001\n","Epoch 2/50\n","781/781 [==============================] - 86s 110ms/step - loss: 2.3027 - accuracy: 0.0973 - val_loss: 2.3025 - val_accuracy: 0.1001\n","Epoch 3/50\n","781/781 [==============================] - 83s 106ms/step - loss: 2.3038 - accuracy: 0.0978 - val_loss: 2.3027 - val_accuracy: 0.1012\n","Epoch 4/50\n","781/781 [==============================] - 81s 104ms/step - loss: 2.3031 - accuracy: 0.0988 - val_loss: 2.3026 - val_accuracy: 0.1000\n","Epoch 5/50\n","781/781 [==============================] - 82s 104ms/step - loss: 2.3027 - accuracy: 0.0986 - val_loss: 2.3026 - val_accuracy: 0.1000\n","Epoch 6/50\n","781/781 [==============================] - 80s 103ms/step - loss: 2.3027 - accuracy: 0.0981 - val_loss: 2.3026 - val_accuracy: 0.1000\n","313/313 - 4s - loss: 2.3026 - accuracy: 0.1000 - 4s/epoch - 14ms/step\n","Test accuracy: 0.10000000149011612\n"]}],"source":["import tensorflow as tf\n","from tensorflow.keras.datasets import cifar10\n","from tensorflow.keras.layers import Dense, Conv2D, BatchNormalization, Activation, Flatten, Dropout\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras.callbacks import EarlyStopping\n","\n","# Model Architecture\n","# Define the model\n","model = Sequential()\n","\n","model.add(Conv2D(64, (3, 3), padding='same', input_shape=train_images.shape[1:]))\n","model.add(BatchNormalization())\n","model.add(Activation('relu'))\n","\n","model.add(Conv2D(64, (3, 3), padding='same'))\n","model.add(BatchNormalization())\n","model.add(Activation('relu'))\n","\n","model.add(Conv2D(128, (3, 3), padding='same'))\n","model.add(BatchNormalization())\n","model.add(Activation('relu'))\n","\n","model.add(Conv2D(128, (3, 3), padding='same'))\n","model.add(BatchNormalization())\n","model.add(Activation('relu'))\n","\n","model.add(Conv2D(256, (3, 3), padding='same'))\n","model.add(BatchNormalization())\n","model.add(Activation('relu'))\n","\n","model.add(Conv2D(256, (3, 3), padding='same'))\n","model.add(BatchNormalization())\n","model.add(Activation('relu'))\n","\n","model.add(Flatten())\n","model.add(Dense(512))\n","model.add(Activation('relu'))\n","model.add(Dropout(0.5))\n","\n","model.add(Dense(10))\n","model.add(Activation('softmax'))\n","\n","# Compile the model\n","model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n","\n","# Data augmentation\n","datagen_train = ImageDataGenerator(\n","    rotation_range=15,\n","    width_shift_range=0.1,\n","    height_shift_range=0.1,\n","    horizontal_flip=True,\n","    vertical_flip=False,\n",")\n","datagen_train.fit(train_images)\n","\n","# Early stopping\n","early_stop = EarlyStopping(monitor='val_loss', patience=5)\n","\n","# Train the model\n","history = model.fit(datagen_train.flow(train_images, train_labels, batch_size=64),\n","                    steps_per_epoch=len(train_images) / 64, epochs=50, verbose=1,\n","                    validation_data=(test_images, test_labels), callbacks=[early_stop])\n","\n","# Evaluate the model\n","test_loss, test_acc = model.evaluate(test_images, test_labels, verbose=2)\n","print(\"Test accuracy:\", test_acc)\n"]},{"cell_type":"markdown","metadata":{"id":"A9BTAMv3nV4X"},"source":["## Experiment 2\n","\n","ResNet50"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jRRQDQF2nVMn"},"outputs":[],"source":["import tensorflow as tf\n","from tensorflow.keras.layers import GlobalAveragePooling2D, Dense\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.datasets import cifar10\n","from tensorflow.keras.utils import to_categorical\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from PIL import Image\n","\n","# Resize images to match input size of ResNet50\n","def resize_image(img):\n","    return img.resize((224, 224))\n","\n","\n","# Resize images\n","x_train_resized = [resize_image(Image.fromarray(img)) for img in train_images]\n","x_test_resized = [resize_image(Image.fromarray(img)) for img in test_images]\n","\n","# Convert resized images to numpy array\n","x_train_resized = tf.keras.preprocessing.image.img_to_array(x_train_resized)\n","x_test_resized = tf.keras.preprocessing.image.img_to_array(x_test_resized)\n","\n","# Preprocess data\n","x_train_resized = tf.keras.applications.resnet50.preprocess_input(x_train_resized)\n","x_test_resized = tf.keras.applications.resnet50.preprocess_input(x_test_resized)\n","y_train = to_categorical(train_labels, num_classes=10)\n","y_test = to_categorical(test_labels, num_classes=10)\n","\n","# Load pre-trained ResNet50 model\n","base_model = tf.keras.applications.resnet50.ResNet50(include_top=False, weights='imagenet', input_shape=(224, 224, 3))\n","\n","# Freeze all layers of the pre-trained model\n","for layer in base_model.layers:\n","    layer.trainable = False\n","\n","# Create new classification layers\n","x = base_model.output\n","x = GlobalAveragePooling2D()(x)\n","x = Dense(1024, activation='relu')(x)\n","predictions = Dense(10, activation='softmax')(x)\n","\n","# Create new model\n","model = Model(inputs=base_model.input, outputs=predictions)\n","\n","# Compile model\n","model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n","\n","# Train model\n","model.fit(x_train_resized, y_train, batch_size=32, epochs=10, validation_data=(x_test_resized, y_test))\n"]},{"cell_type":"markdown","metadata":{"id":"SGogHif3oWf-"},"source":["## Experiment 3\n","VGG16"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":125186,"status":"ok","timestamp":1681841518334,"user":{"displayName":"Tinku Hore","userId":"01939873183751343085"},"user_tz":-330},"id":"5ZfzJ-NzoZ15","outputId":"e9a52d25-c78e-4a23-9bab-d62a005defa0"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/10\n","782/782 [==============================] - 16s 15ms/step - loss: 1.3661 - accuracy: 0.5246 - val_loss: 1.2832 - val_accuracy: 0.5478\n","Epoch 2/10\n","782/782 [==============================] - 11s 14ms/step - loss: 1.1810 - accuracy: 0.5886 - val_loss: 1.1880 - val_accuracy: 0.5868\n","Epoch 3/10\n","782/782 [==============================] - 12s 16ms/step - loss: 1.1207 - accuracy: 0.6092 - val_loss: 1.1629 - val_accuracy: 0.5900\n","Epoch 4/10\n","782/782 [==============================] - 12s 15ms/step - loss: 1.0721 - accuracy: 0.6249 - val_loss: 1.1491 - val_accuracy: 0.6025\n","Epoch 5/10\n","782/782 [==============================] - 11s 14ms/step - loss: 1.0358 - accuracy: 0.6363 - val_loss: 1.1151 - val_accuracy: 0.6095\n","Epoch 6/10\n","782/782 [==============================] - 12s 15ms/step - loss: 0.9990 - accuracy: 0.6504 - val_loss: 1.1263 - val_accuracy: 0.6044\n","Epoch 7/10\n","782/782 [==============================] - 11s 14ms/step - loss: 0.9673 - accuracy: 0.6621 - val_loss: 1.1146 - val_accuracy: 0.6122\n","Epoch 8/10\n","782/782 [==============================] - 11s 14ms/step - loss: 0.9370 - accuracy: 0.6714 - val_loss: 1.1030 - val_accuracy: 0.6153\n","Epoch 9/10\n","782/782 [==============================] - 11s 14ms/step - loss: 0.9117 - accuracy: 0.6815 - val_loss: 1.1062 - val_accuracy: 0.6128\n","Epoch 10/10\n","782/782 [==============================] - 12s 15ms/step - loss: 0.8847 - accuracy: 0.6914 - val_loss: 1.1015 - val_accuracy: 0.6161\n"]}],"source":["import tensorflow as tf\n","from tensorflow.keras.datasets import cifar10\n","from tensorflow.keras.applications.vgg16 import VGG16\n","from tensorflow.keras.layers import Dense, Flatten\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.utils import to_categorical\n","\n","# Normalize the input images\n","x_train = train_images / 255.0\n","x_test = test_images / 255.0\n","\n","y_train = train_labels\n","y_test = test_labels\n","# Convert the labels to one-hot encoding\n","y_train = to_categorical(y_train)\n","y_test = to_categorical(y_test)\n","\n","# Load the pre-trained VGG16 model without the top layer\n","base_model = VGG16(weights='imagenet', include_top=False, input_shape=(32, 32, 3))\n","\n","# Freeze the weights in the base model\n","for layer in base_model.layers:\n","    layer.trainable = False\n","\n","\n","# Add a new top layer for classification\n","x = Flatten()(base_model.output)\n","x = Dense(256, activation='relu')(x)\n","predictions = Dense(10, activation='softmax')(x)\n","\n","# Create the final model\n","model = Model(inputs=base_model.input, outputs=predictions)\n","\n","\n","# Compile the model\n","model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n","\n","# Train the model\n","history = model.fit(x_train, y_train, batch_size=64, epochs=10, validation_data=(x_test, y_test))\n"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1681841518335,"user":{"displayName":"Tinku Hore","userId":"01939873183751343085"},"user_tz":-330},"id":"mKS0wCQTWzXd"},"outputs":[],"source":["# save the model\n","model.save(\"/content/drive/MyDrive/DL/Assignment1/Saved_models/VGG16_model.h5\")"]},{"cell_type":"markdown","metadata":{"id":"LOFYEAY-dU1w"},"source":["### Hyperparameter Tuning"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":370931,"status":"ok","timestamp":1681841080811,"user":{"displayName":"Tinku Hore","userId":"01939873183751343085"},"user_tz":-330},"id":"Ar93T48kdR4Q","outputId":"35594003-9ec3-43b7-8b59-6a6aa1289fd1"},"outputs":[{"name":"stderr","output_type":"stream","text":["<ipython-input-6-67c605529446>:37: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n","  model = KerasClassifier(build_fn=create_model, verbose=0)\n"]},{"name":"stdout","output_type":"stream","text":["Best: 0.557320 using {'learning_rate': 0.001, 'optimizer': 'adam'}\n","Test score: 0.5658000111579895\n"]}],"source":["from keras.applications.vgg16 import VGG16\n","from keras.wrappers.scikit_learn import KerasClassifier\n","from sklearn.model_selection import GridSearchCV\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import LabelEncoder\n","from tensorflow.keras.utils import to_categorical\n","from tensorflow.keras.layers import Dense, Flatten\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.optimizers import Adam\n","\n","\n","\n","\n","# Normalize the input images\n","X_train = train_images / 255.0\n","X_test = test_images / 255.0\n","\n","y_train = train_labels\n","y_test = test_labels\n","# Convert the labels to one-hot encoding\n","y_train = to_categorical(y_train)\n","y_test = to_categorical(y_test)\n","\n","# Define the VGG16 model\n","def create_model(optimizer='adam', learning_rate=0.001):\n","    model = VGG16(include_top=False, input_shape=(32,32, 3))\n","    for layer in model.layers:\n","        layer.trainable = False\n","    flat_layer = Flatten()(model.layers[-1].output)\n","    class_layer = Dense(128, activation='relu')(flat_layer)\n","    output_layer = Dense(10, activation='softmax')(class_layer)\n","    final_model = Model(inputs=model.inputs, outputs=output_layer)\n","    final_model.compile(optimizer=Adam(learning_rate=learning_rate), loss='categorical_crossentropy', metrics=['accuracy'])\n","    return final_model\n","\n","# Create a KerasClassifier object\n","model = KerasClassifier(build_fn=create_model, verbose=0)\n","\n","# Define the parameter grid\n","param_grid = {'optimizer': ['adam', 'rmsprop'],\n","              'learning_rate': [0.001, 0.01, 0.1]}\n","\n","# Perform Grid Search\n","grid = GridSearchCV(estimator=model, param_grid=param_grid, cv=3)\n","grid_result = grid.fit(X_train, y_train)\n","\n","# Print the best hyperparameters\n","print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n","\n","# Evaluate the best model\n","best_model = grid_result.best_estimator_\n","best_model.fit(X_train, y_train)\n","score = best_model.score(X_test, y_test)\n","print(\"Test score:\", score)"]},{"cell_type":"markdown","metadata":{"id":"Sd5vYrtmsSGN"},"source":["## Experiment 4\n","Inception V3"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1134604,"status":"ok","timestamp":1681842696634,"user":{"displayName":"Tinku Hore","userId":"01939873183751343085"},"user_tz":-330},"id":"RSUpn9wXsVok","outputId":"ccbdb699-7fb8-481d-d020-11d7d236b43a"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/10\n","1562/1562 [==============================] - 113s 68ms/step - loss: 1.2890 - accuracy: 0.5467 - val_loss: 1.1252 - val_accuracy: 0.6021\n","Epoch 2/10\n","1562/1562 [==============================] - 106s 68ms/step - loss: 1.1586 - accuracy: 0.5914 - val_loss: 1.0643 - val_accuracy: 0.6241\n","Epoch 3/10\n","1562/1562 [==============================] - 104s 66ms/step - loss: 1.1228 - accuracy: 0.6018 - val_loss: 1.0438 - val_accuracy: 0.6314\n","Epoch 4/10\n","1562/1562 [==============================] - 107s 69ms/step - loss: 1.0952 - accuracy: 0.6102 - val_loss: 1.0194 - val_accuracy: 0.6438\n","Epoch 5/10\n","1562/1562 [==============================] - 103s 66ms/step - loss: 1.0869 - accuracy: 0.6169 - val_loss: 1.0075 - val_accuracy: 0.6467\n","Epoch 6/10\n","1562/1562 [==============================] - 103s 66ms/step - loss: 1.0660 - accuracy: 0.6244 - val_loss: 1.0065 - val_accuracy: 0.6466\n","Epoch 7/10\n","1562/1562 [==============================] - 105s 67ms/step - loss: 1.0571 - accuracy: 0.6272 - val_loss: 1.0099 - val_accuracy: 0.6447\n","Epoch 8/10\n","1562/1562 [==============================] - 102s 65ms/step - loss: 1.0464 - accuracy: 0.6291 - val_loss: 0.9941 - val_accuracy: 0.6534\n","Epoch 9/10\n","1562/1562 [==============================] - 102s 66ms/step - loss: 1.0313 - accuracy: 0.6337 - val_loss: 1.0044 - val_accuracy: 0.6508\n","Epoch 10/10\n","1562/1562 [==============================] - 101s 65ms/step - loss: 1.0356 - accuracy: 0.6341 - val_loss: 0.9964 - val_accuracy: 0.6546\n","Test loss: 0.9964041709899902\n","Test accuracy: 0.6546000242233276\n"]}],"source":["from tensorflow.keras.datasets import cifar10\n","from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.applications.inception_v3 import InceptionV3, preprocess_input\n","from tensorflow.keras.utils import to_categorical\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","\n","# # Load the CIFAR-10 dataset\n","# (X_train, y_train), (X_test, y_test) = cifar10.load_data()\n","\n","# Preprocess the input data\n","X_train = preprocess_input(train_images)\n","X_test = preprocess_input(test_images)\n","y_train = to_categorical(train_labels, num_classes=10)\n","y_test = to_categorical(test_labels, num_classes=10)\n","\n","\n","# Resize the images to 75x75\n","X_train_resized = tf.image.resize(X_train, [75, 75])\n","X_test_resized = tf.image.resize(X_test, [75, 75])\n","\n","# Create the pre-trained model\n","base_model = InceptionV3(weights='imagenet', include_top=False, input_shape=(75,75,3))\n","\n","# Add a global average pooling layer\n","x = base_model.output\n","x = GlobalAveragePooling2D()(x)\n","\n","# Add a fully connected layer with 256 units and ReLU activation\n","x = Dense(256, activation='relu')(x)\n","\n","# Add a final softmax layer for classification\n","predictions = Dense(10, activation='softmax')(x)\n","\n","# Combine the base model and the new layers to create the model\n","model = Model(inputs=base_model.input, outputs=predictions)\n","\n","# Freeze the base layers to prevent them from being updated during training\n","for layer in base_model.layers:\n","    layer.trainable = False\n","\n","# Compile the model\n","model.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n","\n","# Create an ImageDataGenerator for data augmentation\n","datagen = ImageDataGenerator(\n","    rotation_range=20,\n","    width_shift_range=0.2,\n","    height_shift_range=0.2,\n","    horizontal_flip=True\n",")\n","\n","# Train the model using the augmented data\n","history = model.fit(\n","    datagen.flow(X_train_resized, y_train, batch_size=32),\n","    steps_per_epoch=len(X_train) / 32,\n","    epochs=10,\n","    validation_data=(X_test_resized, y_test)\n",")\n","\n","# Evaluate the model on the test data\n","score = model.evaluate(X_test_resized, y_test, verbose=0)\n","print('Test loss:', score[0])\n","print('Test accuracy:', score[1])\n"]},{"cell_type":"code","execution_count":10,"metadata":{"executionInfo":{"elapsed":1271,"status":"ok","timestamp":1681842697895,"user":{"displayName":"Tinku Hore","userId":"01939873183751343085"},"user_tz":-330},"id":"3JNmyLIAtQxE"},"outputs":[],"source":["# save model\n","model.save(\"/content/drive/MyDrive/DL/Assignment1/Saved_models/inceptionV3_model.h5\")"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# **Prediction**\n"]},{"cell_type":"markdown","metadata":{},"source":[]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["1/1 [==============================] - 1s 1s/step\n"]}],"source":["import numpy as np\n","from tensorflow.keras.models import load_model\n","from tensorflow.keras.preprocessing.image import load_img, img_to_array\n","from tensorflow.keras.utils import to_categorical\n","\n","# Load saved model\n","model = load_model('Saved_models/inceptionV3_model.h5')\n","\n","# Load test image\n","image_path = 'ship8.png'\n","image = load_img(image_path, target_size=(75,75))\n","image = img_to_array(image)\n","image = image.astype('float32') / 255.0\n","image = np.expand_dims(image, axis=0)\n","\n","# Make prediction\n","predictions = model.predict(image)"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Predicted class: ship\n","Probability: 0.992682158946991\n"]}],"source":["cifar10_classes = ['airplane', 'automobile', 'bird', 'cat', 'deer',\n","                   'dog', 'frog', 'horse', 'ship', 'truck']\n","\n","# Get predicted class and probability\n","class_idx = np.argmax(predictions)\n","class_label = cifar10_classes[class_idx]\n","probability = predictions[0][class_idx]\n","\n","# Print results\n","print(f'Predicted class: {class_label}')\n","print(f'Probability: {probability}')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":["aONm91peJmob","ltfgeC6TOTxg","A9BTAMv3nV4X"],"provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.6"},"orig_nbformat":4},"nbformat":4,"nbformat_minor":0}
